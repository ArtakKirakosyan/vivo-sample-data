{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#VIVO ingest with Python\n",
      "\n",
      "A common scenario is that a VIVO implementation team will receive an export data from a system of record in CSV or TSV format.  This data will then need to be cleaned and mapped into the VIVO ontology.  This respository contains sample files for faculty, organization, and position data.  We will demonstrate how to map (minimally) this data in to the [VIVO-ISF ontology](https://wiki.duraspace.org/display/VIVO/VIVO-ISF+Ontology) using Python.  \n",
      "\n",
      "###Tools/requirements\n",
      " * [RDFLib](https://rdflib.readthedocs.org/en/latest/)\n",
      "\n",
      "##Faculty\n",
      "\n",
      "For demonstration purposes, lets take the first 5 rows of the CSV file that contains faculty data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head -n 5 data/person_tamu.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Read the CSV file of sample data\n",
      "\n",
      "The read_file function is a reusable block of code that strips empty cells and any line breaks that might appear in the CSV file.  You will probably develop your own similar routine for cleaning CSV data as you become familiar with the types of data problems or inconsistencies that arise from your sources.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from utils import read_file, ns_mgr\n",
      "from pprint import pprint\n",
      "\n",
      "faculty = read_file('data/faculty.csv')\n",
      "pprint(faculty[:5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Create RDF\n",
      "\n",
      "Iterate through the CSV data.  Create a URI for each faculty member from the UID and an rdfs:label.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from rdflib import Graph, Namespace, URIRef, Literal, RDF, RDFS\n",
      "\n",
      "#Our data namespace\n",
      "D = Namespace('http://vivo.school.edu/individual/')\n",
      "#The VIVO namespace\n",
      "VIVO = Namespace('http://vivoweb.org/ontology/core#')\n",
      "\n",
      "#Create an RDFLib Graph\n",
      "g = Graph()\n",
      "#Namespace bindings\n",
      "g.bind('vivo', VIVO)\n",
      "\n",
      "for fac in faculty:\n",
      "    id = fac['UID']\n",
      "    #Make a uri\n",
      "    uri = D['fac{}'.format(id)]\n",
      "    #type\n",
      "    g.add((uri, RDF.type, VIVO.FacultyMember))\n",
      "    #label\n",
      "    g.add((uri, RDFS.label, Literal(fac['FullName'])))\n",
      "#print as turtle\n",
      "print g.serialize(format='turtle')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A URI and a rdfs:label is the minimal amount of data need to create an entity in VIVO.  After loading this into VIVO you will be able to browse the entities using the VIVO interface and can use the interface to make additional assertions.\n",
      "\n",
      "###Add the data to VIVO\n",
      "\n",
      "####via the web interface\n",
      "The VIVO web application allows for uploading prepared RDF files into the triple store.\n",
      "\n",
      "![Add remove](./files/images/add_remove_rdf.png)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####The SPARQL Update API \n",
      "The [VIVO SPARQL Update API](https://wiki.duraspace.org/display/VIVO/The+SPARQL+Update+API) allows you to write data back to VIVO using the W3C [SPARQL 1.1](http://www.w3.org/TR/sparql11-query/).  This was added to VIVO in version 1.6.  \n",
      "\n",
      "Included in this sample code is a utility for writing RDFLib graphs to a VIVO 1.6 instance using the update API."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from utils import VUpdate\n",
      "vstore = VUpdate()\n",
      "vstore.add(g)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Organizations\n",
      "\n",
      "Ingesting organizational units from a CSV would follow a similar path.  \n",
      "\n",
      "Make a sample file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "organizations = read_file('data/organizations.csv')\n",
      "pprint(organizations[:5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can see that the organization data is slightly different.  There is a name, an identifier, but also someone has assigned a VIVO class type to each row.  We can use Python to convert that string into a URI.  With actual data, you might have a string type, such as \"Center\" or \"School\" that you would then need to map to a class type from an ontology. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Create a new empty graph for the organizations.\n",
      "g = Graph()\n",
      "g.bind('vivo', VIVO)\n",
      "\n",
      "for item in organizations[:5]:\n",
      "    org_uri = D['org{}'.format(item['org_ID'])]\n",
      "    org_type = URIRef(item['org_vivo_uri'])\n",
      "    g.add( (org_uri, RDF.type, org_type) )\n",
      "    g.add( (org_uri, RDFS.label, Literal(item['org_name'])) )\n",
      "\n",
      "print g.serialize(format='turtle')\n",
      "          "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Positions\n",
      "We have all the tools we need to map the positions CSV to RDF but our process will be slightly different because we want to connect the people to their position and the position to its organization."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "positions = read_file('data/positions.csv')\n",
      "pprint(positions[:5])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "![ISF positions relations](https://wiki.duraspace.org/download/attachments/51052815/PeoplePositionsOrgs.2014-03-05.png?version=1&modificationDate=1395102709125&api=v2)\n",
      "\n",
      "See other VIVO-ISF relationship diagrams: https://wiki.duraspace.org/display/VIVO/VIVO-ISF+1.6+Relationship+Diagrams\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#initialize an empty Graph\n",
      "g = Graph()\n",
      "g.bind('vivo', VIVO)\n",
      "\n",
      "from rdflib import BNode\n",
      "\n",
      "for pos in positions[:5]:\n",
      "    position_uri = BNode()\n",
      "    faculty_uri = D['fac{}'.format(pos['UID'])]\n",
      "    org_uri = D['org{}'.format(pos['org_ID'])]\n",
      "    g.add( (position_uri, RDF.type, VIVO.FacultyPosition) )\n",
      "    g.add( (position_uri, RDFS.label, Literal(pos['job_title'])) )\n",
      "    #Relate the position to the faculty member and organization.\n",
      "    g.add( (position_uri, VIVO.relates, faculty_uri) )\n",
      "    g.add( (position_uri, VIVO.relates, org_uri) )\n",
      "\n",
      "print g.serialize(format='turtle')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Creating URIs\n",
      "As you can see from both the raw position CSV and the output we don't have a unique identifier for the positions.  This is challenge you will often face when working with VIVO data.  \n",
      "\n",
      "In the example code block above, we created [Blank Nodes](http://en.wikipedia.org/wiki/Blank_node) since these are \"anonymous resources\" but VIVO, and other triple stores, don't like Blank Nodes.  \n",
      "\n",
      "One technique would be to create [URL Slugs](http://patterns.dataincubator.org/book/url-slug.html) based on uniquely identifying information.  This could lead to collisions - two resources being assigned the same URI - but that is not always a bad thing.  You can have separate routines that identify problematic data and flag it for human review.  For example, DbPedia uses this technique.  The URI for Harvard Universty is `http://dbpedia.org/resource/Harvard_University`.  This has worked well for organization names and even journal titles at Brown.  But in this example, a URL Slug would become too verbose.\n",
      "\n",
      "Using standard Python libraries, we will mint a unique identifier for the position by creating an MD5 hash of the person id, organization id, and job title.  This isn't perfect (e.g. if the position title changes, a new URI and therefore a new position will be created) but is a reasonable starting point. \n",
      "\n",
      "Here is the code above but the BNodes have been removed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#initialize an empty Graph\n",
      "from utils import hash_uri\n",
      "\n",
      "g = Graph()\n",
      "g.bind('vivo', VIVO)\n",
      "\n",
      "from rdflib import BNode\n",
      "\n",
      "for pos in positions[:5]:\n",
      "    fac_id = pos['UID']\n",
      "    org_id = pos['org_ID']\n",
      "    title = pos['job_title']\n",
      "    \n",
      "    uri_parts = \"{}{}{}\".format(fac_id, org_id, title)\n",
      "    position_uri = D[hash_uri(uri_parts, prefix='pos')]\n",
      "    \n",
      "    faculty_uri = D['fac{}'.format(fac_id)]\n",
      "    org_uri = D['org{}'.format(org_id)]\n",
      "    \n",
      "    g.add( (position_uri, RDF.type, VIVO.FacultyPosition) )\n",
      "    g.add( (position_uri, RDFS.label, Literal(title)) )\n",
      "    #Relate the position to the faculty member and organization.\n",
      "    g.add( (position_uri, VIVO.relates, faculty_uri) )\n",
      "    g.add( (position_uri, VIVO.relates, org_uri) )\n",
      "\n",
      "print g.serialize(format='turtle')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}